{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-living",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from munch import Munch\n",
    "from PIL import Image, ImageDraw, ImageOps\n",
    "\n",
    "import git\n",
    "\n",
    "repo = git.Repo(Path(\".\").absolute(), search_parent_directories=True)\n",
    "ROOT = Path(repo.working_tree_dir)\n",
    "\n",
    "# Path to the folder where emoji image files are stored\n",
    "images_path = ROOT / \"emoji-images\" / \"imgs\"\n",
    "# Extract the unicodes from the image file names\n",
    "image_unicodes = set(p.stem for p in images_path.glob(\"*.png\"))\n",
    "\n",
    "# Path to the folder where emoji names and unicodes are stored\n",
    "emojis_path = ROOT / \"emojis\" / \"emojis.json\"\n",
    "# Load the emoji data\n",
    "with open(emojis_path, \"r\") as f:\n",
    "    emojis = json.load(f)[\"emojis\"]\n",
    "\n",
    "# A dictionary that assigns a name to each unicode with a corresponding image.\n",
    "unicode2emoji_name = {\n",
    "    unicode: entry[\"name\"]\n",
    "    for entry in emojis\n",
    "    if (unicode := entry[\"unicode\"].replace(\" \", \"-\")) in image_unicodes\n",
    "    and entry[\"name\"]\n",
    "}\n",
    "\n",
    "emoji_name2unicode = {\n",
    "    unicode2emoji_name[unicode]: unicode for unicode in unicode2emoji_name\n",
    "}\n",
    "emoji_names = list(emoji_name2unicode.keys())\n",
    "\n",
    "\n",
    "def load_emoji(emoji_name, size=(32, 32)):\n",
    "    \"\"\"Load the emojis.\"\"\"\n",
    "    unicode = emoji_name2unicode[emoji_name]\n",
    "    image = Image.open(images_path / (unicode + \".png\")).convert(\"RGBA\").resize(size)\n",
    "    return image\n",
    "\n",
    "\n",
    "def get_mask(image_array, threshold=None) -> np.array:\n",
    "    \"\"\"Return the mask of the image. The mask is obtained from the alpha channel.\n",
    "\n",
    "    :param image_array: An array of shape (H x W x 4) representing an RGBA image.\n",
    "    :param threshold: determines the threshold for deciding whether to assign a pixel\n",
    "        to foreground or background. 4 is a good value. Higher values might not for\n",
    "        example get the correct mask for the emoji \"cigarette\" (unicode: 1f6ac).\n",
    "    :returns: The mask of the input image.\n",
    "    \"\"\"\n",
    "    if threshold is None:\n",
    "        threshold = 4\n",
    "    mask_array = image_array[:, :, 3]\n",
    "    mask_array[mask_array < threshold] = 0  # background\n",
    "    mask_array[mask_array >= threshold] = 255  # foreground\n",
    "    return mask_array.astype(bool)\n",
    "\n",
    "\n",
    "def get_bbox(image_array):\n",
    "    \"\"\"Get the bounding boxes of the mask_array.\"\"\"\n",
    "    mask_array = get_mask(image_array)\n",
    "    x_proj = mask_array.any(axis=0)  # Does the column contain a non-zero entry?\n",
    "    y_proj = mask_array.any(axis=1)  # Does the row contain a non-zero entry?\n",
    "    bbox = Munch(\n",
    "        left=x_proj.argmax(),\n",
    "        bottom=y_proj.argmax(),\n",
    "        right=len(x_proj) - 1 - x_proj[::-1].argmax(),\n",
    "        top=len(y_proj) - 1 - y_proj[::-1].argmax(),\n",
    "    )\n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image2array(image):\n",
    "    # alway flip the y-axis when converting between image and array\n",
    "    return np.array(image)[::-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array2image(array):\n",
    "    # alway flip the y-axis when converting between image and array\n",
    "    return Image.fromarray(array[::-1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(image):\n",
    "    image_array = image2array(image)\n",
    "    bbox = get_bbox(image_array)\n",
    "    image_array = image_array[bbox.bottom : bbox.top + 1, bbox.left : bbox.right + 1]\n",
    "    image = array2image(image_array)\n",
    "    x_max, y_max = image_array.shape[1] - 1, image_array.shape[0] - 1\n",
    "    fbbox = np.array(\n",
    "        [\n",
    "            [0, 0],\n",
    "            [0, y_max],\n",
    "            [x_max, y_max],\n",
    "            [x_max, 0],\n",
    "        ]\n",
    "    )\n",
    "    return image, image_array, fbbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def draw(entities, canvas):\n",
    "#     \"\"\"Draw the objects on a canvas.\"\"\"\n",
    "#     for entity in entities:\n",
    "#         canvas.alpha_composite(\n",
    "#             entity.image,\n",
    "#             (entity.bottom_left[0], canvas.size[1] - entity.top_left[1]),\n",
    "#         )\n",
    "#     return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entity:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name=None,\n",
    "        absolute_direction=False,\n",
    "        p=(0, 0),\n",
    "        theta=0,\n",
    "        size=(32, 32),\n",
    "    ):\n",
    "        self.name = name\n",
    "        self.absolute_direction = absolute_direction\n",
    "\n",
    "        self.image = load_emoji(name, size=size)\n",
    "        self.image, self.image_array, self.flt_bbox = crop_image(self.image)\n",
    "\n",
    "        self.p = p\n",
    "        self.theta = theta\n",
    "        self.center = (self.flt_bbox[2] - self.flt_bbox[0]) / 2 + self.flt_bbox[0]\n",
    "        self.rotate(self.theta)\n",
    "        self.translate(self.p)\n",
    "\n",
    "    def rotate(self, theta):\n",
    "        c, s = np.cos(theta), np.sin(theta)\n",
    "        R = np.array([[c, -s], [s, c]])\n",
    "\n",
    "        self.image = self.image.rotate(\n",
    "            360 * theta / (2 * math.pi),\n",
    "            expand=True,\n",
    "        )\n",
    "        self.image_array = image2array(self.image)\n",
    "        if self.absolute_direction:\n",
    "            self.image, self.image_array, self.flt_bbox = crop_image(self.image)\n",
    "        else:  # objects have intrinsic orientations\n",
    "            self.flt_bbox = (self.flt_bbox - self.center) @ R.transpose() + self.center\n",
    "\n",
    "    def translate(self, p):\n",
    "        self.flt_bbox += np.array(p)\n",
    "\n",
    "    def draw(\n",
    "        self,\n",
    "        base,\n",
    "        show_bbox=False,\n",
    "        bbox_color=None,\n",
    "        bbox_border=None,\n",
    "        orientation_marker=False,\n",
    "    ):\n",
    "        d = ImageDraw.Draw(base)\n",
    "\n",
    "        if show_bbox:\n",
    "            d.polygon(\n",
    "                [(p[0], base.size[1] - p[1]) for p in self.bbox],\n",
    "                fill=bbox_color if bbox_color else None,\n",
    "                outline=bbox_border if bbox_border else None,\n",
    "            )\n",
    "\n",
    "        if orientation_marker:\n",
    "            # Use the tenth of the bounding box (from the top) for marking the front side of an self.\n",
    "            bottom_left = (\n",
    "                ((self.flt_bbox[0] - self.flt_bbox[1]) / 10 + self.flt_bbox[1])\n",
    "                .round()\n",
    "                .astype(int)\n",
    "            )\n",
    "            bottom_right = (\n",
    "                ((self.flt_bbox[3] - self.flt_bbox[2]) / 10 + self.flt_bbox[2])\n",
    "                .round()\n",
    "                .astype(int)\n",
    "            )\n",
    "            vertices = [bottom_left, self.top_left, self.top_right, bottom_right]\n",
    "            d.polygon(\n",
    "                [(p[0], base.size[1] - p[1]) for p in vertices],\n",
    "                fill=\"white\",\n",
    "            )\n",
    "        # merge the entity image and the base\n",
    "        base.alpha_composite(\n",
    "            self.image,\n",
    "            (self.bbox[:, 0].min(), base.size[1] - self.bbox[:, 1].max()),\n",
    "        )\n",
    "        return base\n",
    "\n",
    "    @property\n",
    "    def bbox(self):\n",
    "        \"\"\"Round the oringinal bbox coordinates.\"\"\"\n",
    "        return self.flt_bbox.round().astype(int)\n",
    "\n",
    "    @property\n",
    "    def bottom_left(self):\n",
    "        return self.bbox[0]\n",
    "\n",
    "    @property\n",
    "    def top_left(self):\n",
    "        return self.bbox[1]\n",
    "\n",
    "    @property\n",
    "    def top_right(self):\n",
    "        return self.bbox[2]\n",
    "\n",
    "    @property\n",
    "    def bottom_right(self):\n",
    "        return self.bbox[3]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.name}: {', '.join(str(tuple(p)) for p in self.bbox)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-fishing",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = Entity(name=\"octopus\", p=(15, 60), theta=0 * 2 * math.pi, size=(64, 64))\n",
    "canvas = Image.new(\"RGBA\", (224, 224), (127, 127, 127, 127))\n",
    "entity.draw(canvas, show_bbox=True)\n",
    "entity = Entity(name=\"trophy\", p=(90, 60), theta=0.25 * 2 * math.pi, size=(64, 64))\n",
    "entity.draw(canvas, show_bbox=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-least",
   "metadata": {},
   "source": [
    "# Test the Class Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-contemporary",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "from qsr_learning.data.bounding_box_data import above, below, left_of, right_of\n",
    "\n",
    "\n",
    "@interact(\n",
    "    x1=(0, 150), y1=(0, 150), theta1=(0, 360), x2=(0, 150), y2=(0, 150), theta2=(0, 360)\n",
    ")\n",
    "def test_spatial_relations(x1=64, y1=64, theta1=0, x2=128, y2=128, theta2=0):\n",
    "    canvas = Image.new(\"RGBA\", (224, 224), (127, 127, 127, 127))\n",
    "    entity1 = Entity(\n",
    "        name=\"octopus\",\n",
    "        absolute_direction=False,\n",
    "        p=(x1, y1),\n",
    "        theta=theta1 / 360 * 2 * math.pi,\n",
    "        size=(32, 32),\n",
    "    )\n",
    "    entity1.draw(canvas, show_bbox=True, orientation_marker=True)\n",
    "    entity2 = Entity(\n",
    "        name=\"trophy\",\n",
    "        absolute_direction=False,\n",
    "        p=(x2, y2),\n",
    "        theta=theta2 / 360 * 2 * math.pi,\n",
    "        size=(32, 32),\n",
    "    )\n",
    "    entity2.draw(canvas, show_bbox=True, orientation_marker=False)\n",
    "    display(canvas)\n",
    "\n",
    "    for relation in [left_of, right_of, above, below]:\n",
    "        if relation(entity1, entity2):\n",
    "            print(entity1.name, relation.__name__, entity2.name)\n",
    "    for relation in [left_of, right_of, above, below]:\n",
    "        if relation(entity2, entity1):\n",
    "            print(entity2.name, relation.__name__, entity1.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-width",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-cargo",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
