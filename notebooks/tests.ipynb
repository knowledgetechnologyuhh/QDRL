{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from ipywidgets import interact\n",
    "\n",
    "# from qsr_learning.data.data import draw, generate_objects\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the `Entity` Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from PIL import Image\n",
    "from qsr_learning.entity import Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = Image.new(\"RGBA\", (224, 224), (127, 127, 127, 127))\n",
    "entity1 = Entity(\n",
    "    name=\"octopus\",\n",
    "    frame_of_reference=\"absolute\",\n",
    "    p=(30, 30),\n",
    "    theta=0 / 360 * 2 * math.pi,\n",
    "    size=(32, 32),\n",
    ")\n",
    "entity1.draw(canvas, add_bbox=True, add_front=True)\n",
    "entity2 = Entity(\n",
    "    name=\"trophy\",\n",
    "    frame_of_reference=\"absolute\",\n",
    "    p=(60, 60),\n",
    "    theta=90 / 360 * 2 * math.pi,\n",
    "    size=(32, 32),\n",
    ")\n",
    "entity2.draw(canvas, add_bbox=True, add_front=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "from qsr_learning.binary_relation import above, below, left_of, right_of\n",
    "from qsr_learning.data import DRLDataset\n",
    "\n",
    "import math\n",
    "from PIL import Image\n",
    "from qsr_learning.entity import Entity\n",
    "\n",
    "\n",
    "@interact(\n",
    "    frame_of_reference=(0, 1),\n",
    "    x1=(0, 150),\n",
    "    y1=(0, 150),\n",
    "    theta1=(0, 360),\n",
    "    x2=(0, 150),\n",
    "    y2=(0, 150),\n",
    "    theta2=(0, 360),\n",
    ")\n",
    "def test_spatial_relations(\n",
    "    frame_of_reference=0, x1=64, y1=64, theta1=0, x2=128, y2=128, theta2=150\n",
    "):\n",
    "    canvas = Image.new(\"RGBA\", (224, 224), (0, 0, 0, 255))\n",
    "    entity1 = Entity(\n",
    "        name=\"octopus\",\n",
    "        frame_of_reference={0: \"absolute\", 1: \"intrinsic\"}[frame_of_reference],\n",
    "        p=(x1, y1),\n",
    "        theta=theta1 / 360 * 2 * math.pi,\n",
    "        size=(32, 32),\n",
    "    )\n",
    "    entity1.draw(canvas, add_bbox=True, add_front=True)\n",
    "    entity2 = Entity(\n",
    "        name=\"trophy\",\n",
    "        frame_of_reference={0: \"absolute\", 1: \"intrinsic\"}[frame_of_reference],\n",
    "        p=(x2, y2),\n",
    "        theta=theta2 / 360 * 2 * math.pi,\n",
    "        size=(32, 32),\n",
    "    )\n",
    "    entity2.draw(canvas, add_bbox=True, add_front=True)\n",
    "    background = Image.new(\"RGBA\", canvas.size, (0, 0, 0))\n",
    "    image = Image.alpha_composite(background, canvas).convert(\"RGB\")\n",
    "    display(image)\n",
    "\n",
    "    for relation in [left_of, right_of, above, below]:\n",
    "        if relation(entity1, entity2):\n",
    "            print(entity1.name, relation.__name__, entity2.name)\n",
    "    for relation in [left_of, right_of, above, below]:\n",
    "        if relation(entity2, entity1):\n",
    "            print(entity2.name, relation.__name__, entity1.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "from qsr_learning.ternary_relation import in_front_of, behind, left_of, right_of\n",
    "\n",
    "@interact(\n",
    "    x1=(0, 190),\n",
    "    y1=(0, 190),\n",
    "    theta1=(0, 360),\n",
    "    x2=(0, 150),\n",
    "    y2=(0, 150),\n",
    "    theta2=(0, 360),\n",
    "    x3=(0, 150),\n",
    "    y3=(0, 150),\n",
    "    theta3=(0, 360),\n",
    ")\n",
    "def test_spatial_relations(\n",
    "    x1=32, y1=32, theta1=0, x2=64, y2=64, theta2=150, x3=128, y3=128, theta3=150\n",
    "):\n",
    "    canvas = Image.new(\"RGBA\", (224, 224), (127, 127, 127, 127))\n",
    "\n",
    "    entity1 = Entity(\n",
    "        name=\"octopus\",\n",
    "        frame_of_reference=\"relative\",\n",
    "        p=(x1, y1),\n",
    "        theta=theta1 / 360 * 2 * math.pi,\n",
    "        size=(32, 32),\n",
    "    )\n",
    "    entity1.draw(canvas, add_bbox=False, add_front=False)\n",
    "\n",
    "    entity2 = Entity(\n",
    "        name=\"trophy\",\n",
    "        frame_of_reference=\"relative\",\n",
    "        p=(x2, y2),\n",
    "        theta=theta2 / 360 * 2 * math.pi,\n",
    "        size=(32, 32),\n",
    "    )\n",
    "    entity2.draw(canvas, add_bbox=False, add_front=False)\n",
    "\n",
    "    entity3 = Entity(\n",
    "        name=\"lion\",\n",
    "        frame_of_reference=\"relative\",\n",
    "        p=(x3, y3),\n",
    "        theta=theta3 / 360 * 2 * math.pi,\n",
    "        size=(32, 32),\n",
    "    )\n",
    "    entity3.draw(canvas, add_bbox=False, add_front=False)\n",
    "\n",
    "    display(canvas)\n",
    "    if left_of(entity1, entity2, entity3):\n",
    "        print(entity1.name, \"left_of\", entity2.name, \"as_seen_from\", entity3.name)\n",
    "    if right_of(entity1, entity2, entity3):\n",
    "        print(entity1.name, \"right_of\", entity2.name, \"as_seen_from\", entity3.name)\n",
    "    if in_front_of(entity1, entity2, entity3):\n",
    "        print(entity1.name, \"in_front_of\", entity2.name, \"as_seen_from\", entity3.name)\n",
    "    if behind(entity1, entity2, entity3):\n",
    "        print(entity1.name, \"behind\", entity2.name, \"as_seen_from\", entity3.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsr_learning.data import draw_entities, generate_entities\n",
    "from qsr_learning.entity import emoji_names\n",
    "\n",
    "entities = generate_entities(\n",
    "    entity_names=emoji_names[:5],\n",
    "    frame_of_reference=\"absolute\",\n",
    "    w_range=(32, 32),\n",
    "    h_range=(32, 32),\n",
    ")\n",
    "image = draw_entities(entities, add_bbox=True, add_front=False)\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "from ipywidgets import interact\n",
    "from PIL import Image\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from qsr_learning.data import DRLDataset\n",
    "from qsr_learning.entity import emoji_names\n",
    "\n",
    "entity_names = [\n",
    "    \"slightly smiling face\",\n",
    "    \"nerd face\",\n",
    "    \"smiling face with halo\",\n",
    "    \"expressionless face\",\n",
    "    \"flushed face\",\n",
    "    \"face with tears of joy\",\n",
    "    \"neutral face\",\n",
    "    \"smiling face with heart-eyes\",]\n",
    "relation_names = [\"left_of\", \"right_of\", \"above\", \"below\"]\n",
    "dataset = DRLDataset(\n",
    "    vocab=entity_names + relation_names +['as_seen_from'],\n",
    "    entity_names=entity_names,\n",
    "    excluded_entity_names=[\"slightly smiling face\", \"nerd face\", \"expressionless face\"],\n",
    "    relation_names=relation_names,\n",
    "    excluded_relation_names=[\"left_of\", \"right_of\", \"above\", \"below\"],\n",
    "    num_entities=5,\n",
    "    frame_of_reference=\"absolute\",\n",
    "    w_range=(24, 24),\n",
    "    h_range=(24, 24),\n",
    "    theta_range=(0, 2 * math.pi),\n",
    "    add_bbox=False,\n",
    "    add_front=False,\n",
    "    transform=None,\n",
    "    canvas_size=(128, 128),\n",
    "    num_samples=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(idx=(0, len(dataset) - 1))\n",
    "def display_sample(idx=0):\n",
    "\n",
    "    image_t, question_t, answer_t = dataset[idx]\n",
    "    image = Image.fromarray(\n",
    "        (255 * (dataset.std.view(-1, 1, 1) * image_t + dataset.mean.view(-1, 1, 1)))\n",
    "        .permute(1, 2, 0)\n",
    "        .numpy()\n",
    "        .astype(\"uint8\")\n",
    "    )\n",
    "\n",
    "    question = [dataset.idx2word[idx] for idx in question_t.tolist()]\n",
    "    answer = bool(answer_t)\n",
    "    display(image)\n",
    "    print(question)\n",
    "    print(\"Ground truth: \", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
