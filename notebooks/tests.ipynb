{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from ipywidgets import interact\n",
    "\n",
    "# from qsr_learning.data.data import draw, generate_objects\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the `Entity` Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from PIL import Image\n",
    "from qsr_learning.entity import Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = Image.new(\"RGBA\", (224, 224), (127, 127, 127, 127))\n",
    "entity1 = Entity(\n",
    "    name=\"octopus\",\n",
    "    frame_of_reference=\"absolute\",\n",
    "    p=(30, 30),\n",
    "    theta=0 / 360 * 2 * math.pi,\n",
    "    size=(32, 32),\n",
    ")\n",
    "entity1.draw(canvas, add_bbox=True, add_front=True)\n",
    "entity2 = Entity(\n",
    "    name=\"trophy\",\n",
    "    frame_of_reference=\"absolute\",\n",
    "    p=(60, 60),\n",
    "    theta=90 / 360 * 2 * math.pi,\n",
    "    size=(32, 32),\n",
    ")\n",
    "entity2.draw(canvas, add_bbox=True, add_front=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "from qsr_learning.relation import above, below, left_of, right_of\n",
    "\n",
    "\n",
    "@interact(\n",
    "    frame_of_reference=(0, 1),\n",
    "    x1=(0, 150),\n",
    "    y1=(0, 150),\n",
    "    theta1=(0, 360),\n",
    "    x2=(0, 150),\n",
    "    y2=(0, 150),\n",
    "    theta2=(0, 360),\n",
    ")\n",
    "def test_spatial_relations(\n",
    "    frame_of_reference=0, x1=64, y1=64, theta1=0, x2=128, y2=128, theta2=150\n",
    "):\n",
    "    canvas = Image.new(\"RGBA\", (224, 224), (127, 127, 127, 127))\n",
    "    entity1 = Entity(\n",
    "        name=\"octopus\",\n",
    "        frame_of_reference={0: \"absolute\", 1: \"intrinsic\"}[frame_of_reference],\n",
    "        p=(x1, y1),\n",
    "        theta=theta1 / 360 * 2 * math.pi,\n",
    "        size=(32, 32),\n",
    "    )\n",
    "    entity1.draw(canvas, add_bbox=True, add_front=True)\n",
    "    entity2 = Entity(\n",
    "        name=\"trophy\",\n",
    "        frame_of_reference={0: \"absolute\", 1: \"intrinsic\"}[frame_of_reference],\n",
    "        p=(x2, y2),\n",
    "        theta=theta2 / 360 * 2 * math.pi,\n",
    "        size=(32, 32),\n",
    "    )\n",
    "    entity2.draw(canvas, add_bbox=True, add_front=True)\n",
    "    display(canvas)\n",
    "\n",
    "    for relation in [left_of, right_of, above, below]:\n",
    "        if relation(entity1, entity2):\n",
    "            print(entity1.name, relation.__name__, entity2.name)\n",
    "    for relation in [left_of, right_of, above, below]:\n",
    "        if relation(entity2, entity1):\n",
    "            print(entity2.name, relation.__name__, entity1.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsr_learning.data import draw_entities, generate_entities\n",
    "from qsr_learning.entity import emoji_names\n",
    "\n",
    "entities = generate_entities(\n",
    "    entity_names=emoji_names,  # [\"octopus\", \"trophy\"],\n",
    "    num_entities=2,\n",
    "    frame_of_reference=\"absolute\",\n",
    "    w_range=(16, 64),\n",
    "    h_range=(16, 64),\n",
    ")\n",
    "image = draw_entities(entities, add_bbox=True, add_front=False)\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "from ipywidgets import interact\n",
    "from PIL import Image\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from qsr_learning.data import DRLDataset\n",
    "from qsr_learning.entity import emoji_names\n",
    "\n",
    "dataset = DRLDataset(\n",
    "    entity_names=[\"octopus\", \"trophy\", \"frog\", \"ghost\"],\n",
    "    excluded_combinations=[(\"octopus\", \"trophy\")],\n",
    "    relation_names=[\"left_of\", \"right_of\"],\n",
    "    num_entities=2,\n",
    "    frame_of_reference=\"intrinsic\",\n",
    "    w_range=(32, 32),\n",
    "    h_range=(32, 32),\n",
    "    theta_range=(0, 2 * math.pi),\n",
    "    add_bbox=True,\n",
    "    add_front=True,\n",
    "    transform=None,\n",
    "    canvas_size=(224, 224),\n",
    "    num_samples=1000,\n",
    ")\n",
    "train_dataset, validation_dataset, test_dataset = random_split(\n",
    "    dataset,\n",
    "    [800, 100, 100],\n",
    "    generator=torch.Generator().manual_seed(0),\n",
    ")\n",
    "subset = train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(idx=(0, len(subset) - 1))\n",
    "def display_sample(idx=0):\n",
    "\n",
    "    image_t, question_t, answer_t = subset[idx]\n",
    "    image = Image.fromarray(\n",
    "        (255 * (dataset.std.view(-1, 1, 1) * image_t + dataset.mean.view(-1, 1, 1)))\n",
    "        .permute(1, 2, 0)\n",
    "        .numpy()\n",
    "        .astype(\"uint8\")\n",
    "    )\n",
    "    head, relation, tail = question_t.tolist()\n",
    "    question = (\n",
    "        dataset.idx2word[head],\n",
    "        dataset.idx2word[relation],\n",
    "        dataset.idx2word[tail],\n",
    "    )\n",
    "    answer = bool(answer_t)\n",
    "    display(image)\n",
    "    print(question)\n",
    "    print(\"Ground truth: \", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
