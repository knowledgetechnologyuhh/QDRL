{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from munch import Munch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from qsr_learning.data import DRLDataset\n",
    "from qsr_learning.models import DRLNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Munch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from qsr_learning.entity import emoji_names\n",
    "\n",
    "# fmt:off\n",
    "entity_names = ['books', 'camel', 'trophy', 'ice cream', 'person rowing boat', 'ring', 'tropical fish', 'crown', 'horse racing', 'spiral shell', 'watch', 'rocket', 'herb', 'radio', 'sun with face', 'cat face', 'soccer ball', 'leopard', 'bathtub', 'closed umbrella', 'folded hands', 'person walking', 'honey pot', 'face with medical mask', 'star', 'sports medal', 'megaphone', 'backpack', 'movie camera', 'ox', 'face screaming in fear', 'mouse face', 'bowling', 'candy', 'bicycle', 'water buffalo']\n",
    "excluded_entities = ['horse racing', 'folded hands'] #, 'backpack', 'soccer ball', 'crown', 'face screaming in fear', 'bowling', 'books', 'star', 'water buffalo', 'rocket', 'person walking', 'closed umbrella', 'mouse face', 'watch', 'honey pot', 'ring', 'candy', 'bathtub']\n",
    "# fmt: on\n",
    "print(\n",
    "    len(entity_names),\n",
    "    len(excluded_entities),\n",
    "    set(excluded_entities).issubset(set(entity_names)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.dataset = Munch(\n",
    "    entity_names=entity_names,\n",
    "    excluded_entities=[],\n",
    "    relation_names=[\"left_of\", \"right_of\", \"above\", \"below\"],\n",
    "    num_entities=2,\n",
    "    frame_of_reference=\"absolute\",\n",
    "    w_range=(16, 16),\n",
    "    h_range=(16, 16),\n",
    "    theta_range=(0, 0),\n",
    "    add_bbox=False,\n",
    "    add_front=False,\n",
    "    transform=None,\n",
    "    canvas_size=(128, 128),\n",
    "    num_samples=10 ** 6,\n",
    "    root_seed=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DRLDataset(\n",
    "    **{\n",
    "        **config.dataset,\n",
    "        **dict(\n",
    "            excluded_entities=excluded_entities,\n",
    "            num_samples=10 ** 6,\n",
    "            root_seed=0,\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "validation_dataset_standard = DRLDataset(\n",
    "    **{\n",
    "        **config.dataset,\n",
    "        **dict(\n",
    "            excluded_entities=excluded_entities,\n",
    "            num_samples=10 ** 4,\n",
    "            root_seed=train_dataset.num_samples,\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "validation_dataset_compositional = DRLDataset(\n",
    "    **{\n",
    "        **config.dataset,\n",
    "        **dict(\n",
    "            entity_names=excluded_entities,\n",
    "            excluded_entities=[],\n",
    "            num_samples=10 ** 4,\n",
    "            root_seed=train_dataset.num_samples\n",
    "            + validation_dataset_standard.num_samples,\n",
    "        ),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.data_loader = Munch(\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, **config.data_loader)\n",
    "validation_loader_standard = DataLoader(\n",
    "    validation_dataset_standard, **{**config.data_loader, \"shuffle\": False}\n",
    ")\n",
    "validation_loader_compositional = DataLoader(\n",
    "    validation_dataset_compositional, **{**config.data_loader, \"shuffle\": False}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model = Munch(\n",
    "    vision_model=\"resnet18\",\n",
    "    image_size=(3, *config.dataset.canvas_size),\n",
    "    num_embeddings=len(train_dataset.word2idx),\n",
    "    embedding_dim=64,\n",
    "    question_len=train_dataset[0][1].shape.numel(),\n",
    "    image_encoder_pretrained=False,\n",
    "    freeze_image_encoder=False,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DRLNet(**config.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.trainer = Munch(\n",
    "    gpus=1,\n",
    "    max_epochs=10,\n",
    "    precision=32,\n",
    "    limit_train_batches=1.0,\n",
    "    limit_val_batches=1.0,\n",
    "    val_check_interval=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import git\n",
    "from git.exc import RepositoryDirtyError\n",
    "from pytorch_lightning import loggers\n",
    "\n",
    "repo = git.Repo(Path(\".\").absolute(), search_parent_directories=True)\n",
    "ROOT = Path(repo.working_tree_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if repo.is_dirty():\n",
    "#     raise RepositoryDirtyError(repo, \"Have you forgotten to commit the changes?\")\n",
    "# sha = repo.head.object.hexsha\n",
    "sha = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_logger = loggers.TensorBoardLogger(save_dir=ROOT / \"lightning_logs\", name=\"\", version=sha)\n",
    "trainer = pl.Trainer(**{**config.trainer, **dict(logger=tb_logger)})\n",
    "trainer.fit(\n",
    "    model, train_loader, [validation_loader_standard, validation_loader_compositional]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
