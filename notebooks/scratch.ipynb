{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from munch import Munch\n",
    "from ray import tune\n",
    "\n",
    "\n",
    "def report_result(epoch, phases, result, data_loader):\n",
    "    log = dict(epoch=epoch)\n",
    "    for phase in phases:\n",
    "        log[phase + \"_loss\"] = result[phase].total_loss / len(\n",
    "            data_loader[phase].dataset\n",
    "        )\n",
    "        log[phase + \"_accuracy\"] = result[phase].num_correct / len(\n",
    "            data_loader[phase].dataset\n",
    "        )\n",
    "    # tune.report(**log)\n",
    "    print(log)\n",
    "\n",
    "\n",
    "def step(model, criterion, optimizer, phase, batch, result, freeze, device):\n",
    "    if phase == \"train\":\n",
    "        model.train()\n",
    "        if freeze == \"all\":\n",
    "            model.image_encoder.eval()\n",
    "        if freeze == \"bn\":  # Common in training object detection models\n",
    "            for layer in model.modules():\n",
    "                if isinstance(layer, nn.BatchNorm2d):\n",
    "                    layer.eval()\n",
    "    else:\n",
    "        model.eval()\n",
    "    torch.autograd.set_grad_enabled(phase == \"train\")\n",
    "    images, questions, answers = (item.to(device) for item in batch)\n",
    "    batch_size = images.shape[0]\n",
    "    model.zero_grad()\n",
    "    out = model(images, questions)\n",
    "    loss = criterion(out, answers.float()) / batch_size\n",
    "    result[phase].total_loss += loss.item()\n",
    "    result[phase].num_correct += ((out > 0.5) == answers).sum().item()\n",
    "    if phase == \"train\":\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from munch import Munch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from qsr_learning.data import DRLDataset, get_mean_and_std\n",
    "from qsr_learning.entity import emoji_names\n",
    "from qsr_learning.models import HadarmardFusionNet\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Munch(\n",
    "    data=Munch(\n",
    "        train=Munch(\n",
    "            #             entity_names=emoji_names,\n",
    "            entity_names=[\"octopus\", \"trophy\"],\n",
    "            relation_names=[\"left_of\", \"right_of\"],\n",
    "            num_entities=2,\n",
    "            frame_of_reference=\"absolute\",\n",
    "            w_range=(32, 32),\n",
    "            h_range=(32, 32),\n",
    "            theta_range=(0, 0),\n",
    "            num_samples=2**10,\n",
    "            shuffle=True,\n",
    "        ),\n",
    "        validation=Munch(\n",
    "            entity_names=[\"octopus\", \"trophy\"],\n",
    "            relation_names=[\"left_of\", \"right_of\"],\n",
    "            num_entities=2,\n",
    "            frame_of_reference=\"absolute\",\n",
    "            w_range=(32, 32),\n",
    "            h_range=(32, 32),\n",
    "            theta_range=(0, 0),  # theta_range=(0, 2 * math.pi),\n",
    "            num_samples=2**10,\n",
    "            shuffle=False,\n",
    "        ),\n",
    "    ),\n",
    "    model=Munch(\n",
    "        ent_dim=10,\n",
    "        rel_dim=10,\n",
    "        cnn_model=\"resnet18\",\n",
    "        pretrained=False,\n",
    "    ),\n",
    "    train=Munch(batch_size=128, num_epochs=100, freeze=\"all\", lr=0.001),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "",
   "metadata": {},
   "outputs": [],
   "source": [
    "phases = [\"train\", \"validation\"]\n",
    "datasets = Munch({phase: DRLDataset(**config.data[phase]) for phase in phases})\n",
    "\n",
    "data_loader = Munch(\n",
    "    {\n",
    "        phase: DataLoader(\n",
    "            datasets[phase],\n",
    "            batch_size=config.train.batch_size,\n",
    "            num_workers=4,\n",
    "        )\n",
    "        for phase in phases\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import trange\n",
    "\n",
    "model = HadarmardFusionNet(datasets.train, **config.model)\n",
    "model.to(device)\n",
    "criterion = nn.BCELoss(reduction=\"sum\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.train.lr)\n",
    "result = Munch()\n",
    "for epoch in trange(config.train.num_epochs):\n",
    "    for phase in phases:\n",
    "        result[phase] = Munch()\n",
    "        result[phase].total_loss = 0\n",
    "        result[phase].num_correct = 0\n",
    "        for batch in data_loader[phase]:\n",
    "            step(\n",
    "                model,\n",
    "                criterion,\n",
    "                optimizer,\n",
    "                phase,\n",
    "                batch,\n",
    "                result,\n",
    "                config.train.freeze,\n",
    "                device,\n",
    "            )\n",
    "    report_result(epoch, phases, result, data_loader)\n",
    "    torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "",
   "metadata": {},
   "outputs": [],
   "source": [
    "phases = [\"train\", \"validation\"]\n",
    "datasets = Munch({phase: DRLDataset(**config.data[phase]) for phase in phases})\n",
    "data_loader = Munch(\n",
    "    {\n",
    "        phase: DataLoader(\n",
    "            datasets[phase],\n",
    "            batch_size=config.train.batch_size,\n",
    "            num_workers=4,\n",
    "        )\n",
    "        for phase in phases\n",
    "    }\n",
    ")\n",
    "\n",
    "for batch in data_loader[\"train\"]:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "@interact(row=(0, 127))\n",
    "def batch2sample(row):\n",
    "    dataset = datasets[\"validation\"]\n",
    "    image_tensor, question_tensor, answer_tensor = (\n",
    "        batch[0][row],\n",
    "        batch[1][row],\n",
    "        batch[2][row],\n",
    "    )\n",
    "    image = Image.fromarray(\n",
    "        (\n",
    "            255\n",
    "            * (dataset.std.view(-1, 1, 1) * image_tensor + dataset.mean.view(-1, 1, 1))\n",
    "        )\n",
    "        .permute(1, 2, 0)\n",
    "        .numpy()\n",
    "        .astype(\"uint8\")\n",
    "    )\n",
    "    head, relation, tail = question_tensor.tolist()\n",
    "    question = (dataset.idx2ent[head], dataset.idx2rel[relation], dataset.idx2ent[tail])\n",
    "    answer = bool(answer_tensor)\n",
    "    display(image)\n",
    "    print(question)\n",
    "    print(\"Ground truth: \", answer)\n",
    "    \n",
    "    prediction = model(image_tensor.unsqueeze(0), question_tensor.unsqueeze(0))\n",
    "    print(\"Prediction: {} (p={:3.2f})\".format(prediction.item() > 0.5, prediction.item()))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
