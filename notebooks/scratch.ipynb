{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from itertools import product\n",
    "from typing import List, Tuple\n",
    "\n",
    "from munch import Munch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start with what you want to have and write tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model receives as its input\n",
    "\n",
    "- An image that is represented by a list of entities, where each entity `e` is an 9-tuple consisting of its name `e.name` and its four bounding box coordinates `e.bbox = (bottom_left, top_left, top_right, bottom_right)`, which comprise the remaining $8 = 4 \\times 2$ entries of the 9-tuple.\n",
    "    - The orientation of each entity is determined by its second and third coordinates.\n",
    "    - To process the input one could use Transformer or graph neural networks, where the graph is supposed to be complete (i.e., each pair of vertices is joined by an edge).\n",
    "- A question that is represented by a triple `(entity1, relation, entity2)` or `(entity1, relation, entity2, entity3)`\n",
    "\n",
    "There may be already an existing model that is similar to this. I would need to check this out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageOps\n",
    "from qsr_learning.data.bounding_box_data import (\n",
    "    above,\n",
    "    below,\n",
    "    generate_entities,\n",
    "    left_of,\n",
    "    right_of,\n",
    ")\n",
    "\n",
    "\n",
    "def draw(entity, base, orientation_marker=True):\n",
    "    d = ImageDraw.Draw(base)\n",
    "    d.polygon(\n",
    "        [tuple(p) for p in entity.bbox],\n",
    "        fill=entity.color if entity.color else (0, 0, 0, 255),\n",
    "    )\n",
    "    # Use the tenth of the bounding box (from the top) for marking the front side of an entity.\n",
    "    if orientation_marker:\n",
    "        bottom_left = ((entity.bbox_float[0] - entity.bbox_float[1]) / 10).astype(\n",
    "            int\n",
    "        ) + entity.top_left\n",
    "        bottom_right = ((entity.bbox_float[3] - entity.bbox_float[2]) / 10).astype(\n",
    "            int\n",
    "        ) + entity.top_right\n",
    "        d.polygon(\n",
    "            [\n",
    "                tuple(p)\n",
    "                for p in (bottom_left, entity.top_left, entity.top_right, bottom_right)\n",
    "            ],\n",
    "            fill=(255, 255, 255, 255),\n",
    "        )\n",
    "    return base\n",
    "\n",
    "\n",
    "def show(entities, base, orientation_marker=True):\n",
    "    for entity in entities:\n",
    "        draw(entity, base)\n",
    "    base = ImageOps.flip(base)\n",
    "    d = ImageDraw.Draw(base)\n",
    "    for entity in entities:\n",
    "        # Add the name\n",
    "        center = (\n",
    "            ((entity.bbox_float[0] - entity.bbox_float[2]) / 2 + entity.bbox_float[2])\n",
    "            .astype(int)\n",
    "            .tolist()\n",
    "        )\n",
    "        d.text(\n",
    "            (center[0]-1, base.size[1] - center[1]-2),\n",
    "            entity.name,\n",
    "            fill=\"pink\",\n",
    "            direction=\"ttb\",\n",
    "        )\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_examples(entities, relations, size=None) -> List[Tuple[str, str, str]]:\n",
    "    \"\"\"\n",
    "    Generate positive examples from a list of entities.\n",
    "\n",
    "    :param entities: a list of entities\n",
    "    :param size: the number of examples to be generated\n",
    "\n",
    "    :returns: a list of triples (entity1, relation, entity2)\n",
    "    \"\"\"\n",
    "    # Generate positive examples\n",
    "    positive_examples = []\n",
    "    negative_examples = []\n",
    "    for entity1, entity2 in product(entities, entities):\n",
    "        if entity1 != entity2:\n",
    "            for rel in relations:\n",
    "                if rel(entity1, entity2):\n",
    "                    positive_examples.append(\n",
    "                        (\n",
    "                            entity1.name,\n",
    "                            rel.__name__,\n",
    "                            entity2.name,\n",
    "                        )\n",
    "                    )\n",
    "                else:\n",
    "                    negative_examples.append(\n",
    "                        (\n",
    "                            entity1.name,\n",
    "                            rel.__name__,\n",
    "                            entity2.name,\n",
    "                        )\n",
    "                    )\n",
    "    return positive_examples, negative_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = generate_entities(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = Image.new(\"RGBA\", (224, 224), (127, 127, 127, 127))\n",
    "display(show(entities, canvas))\n",
    "relations = [left_of, right_of, above, below]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_examples, negative_examples = generate_examples(entities, relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class RelationLearningDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # [entity_id, bottom_left_x, bottom_left_y, top_left_x, top_left_y, top_right_x, top_right_y, bottom_right_x, bottom_right_y]\n",
    "        image = torch.tensor([0, 0, 0, 0, 1, 1, 1, 1, 0], dtype=torch.float)\n",
    "        question = torch.tensor([0, 0, 1], dtype=torch.float)\n",
    "        return image, question\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "loader = DataLoader(RelationLearningDataset(), batch_size=1)\n",
    "\n",
    "for batch in loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont, ImageOps\n",
    "from qsr_learning.data.bounding_box_data import Entity\n",
    "entity1 = Entity(32, 32, p=(32, 32), theta=30)\n",
    "entity2 = Entity(32, 32, p=(64, 64), theta=30)\n",
    "\n",
    "# make a blank image for the text, initialized to transparent text color\n",
    "base = Image.new(\"RGBA\", (224, 224), (127, 127, 127, 127))\n",
    "entity1.draw(base)\n",
    "ImageOps.flip(entity2.draw(base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ipywidgets import interact\n",
    "\n",
    "from qsr_learning.data.bounding_box_data import above, below, left_of, right_of\n",
    "\n",
    "\n",
    "@interact(\n",
    "    x1=(0, 150),\n",
    "    y1=(0, 150),\n",
    "    w1=(10, 150),\n",
    "    h1=(10, 150),\n",
    "    theta1=(0.0, 2 * np.pi, 2 * np.pi / 360),\n",
    "    x2=(0, 150),\n",
    "    y2=(0, 150),\n",
    "    w2=(10, 150),\n",
    "    h2=(10, 150),\n",
    "    theta2=(0.0, 2 * np.pi, 2 * np.pi / 360),\n",
    ")\n",
    "def test_spatial_relations(\n",
    "    x1=3, y1=30, w1=30, h1=30, theta1=0.0, x2=60, y2=60, w2=30, h2=30, theta2=0.0\n",
    "):\n",
    "    base = Image.new(\"RGBA\", (224, 224), (127, 127, 127, 127))\n",
    "    entity1 = Entity(w1, h1, p=(x1, y1), theta=theta1, name=\"green\", color=\"green\")\n",
    "    entity2 = Entity(w2, h2, p=(x2, y2), theta=theta2, name=\"red\", color=\"red\")\n",
    "    entity1.draw(base)\n",
    "    entity2.draw(base)\n",
    "    display(ImageOps.flip(base))\n",
    "    print(entity1)\n",
    "    print(entity2)\n",
    "    print(\n",
    "        \"left_of({}, {}): {}\".format(\n",
    "            entity1.name, entity2.name, left_of(entity1, entity2)\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"right_of({}, {}): {}\".format(\n",
    "            entity1.name, entity2.name, right_of(entity1, entity2)\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"above({}, {}): {}\".format(entity1.name, entity2.name, above(entity1, entity2))\n",
    "    )\n",
    "    print(\n",
    "        \"below({}, {}): {}\".format(entity1.name, entity2.name, below(entity1, entity2))\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
