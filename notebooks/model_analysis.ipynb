{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "informed-practitioner",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "empty-scotland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from munch import Munch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from qsr_learning.data import DRLDataset\n",
    "from qsr_learning.models import DRLNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "requested-strike",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Munch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-amsterdam",
   "metadata": {},
   "source": [
    "## Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "grave-sierra",
   "metadata": {},
   "outputs": [],
   "source": [
    "mac_language_encoder_kwargs = {\n",
    "    'encoder_type': 'lstm',\n",
    "    'decoder_type': 'linear',\n",
    "    'null_token': None,\n",
    "    'encoder_vocab_size': None,\n",
    "    'wordvec_dim': 300,\n",
    "    'hidden_dim': 128,\n",
    "    'rnn_num_layers': 1,\n",
    "    'rnn_dropout': 0,\n",
    "    'parameter_efficient': True,\n",
    "    'output_batchnorm': False,\n",
    "    'bidirectional': True,\n",
    "    'gamma_option': 'linear', # not used\n",
    "    'gamma_baseline': 1, # not used\n",
    "    'use_attention': False, # not used\n",
    "    'taking_context': True,\n",
    "    'variational_embedding_dropout': 0.,\n",
    "    'embedding_uniform_boundary': 1.0,\n",
    "    'module_num_layers': 1,\n",
    "    'num_modules': None, # from the mac model kwargs\n",
    "}\n",
    "\n",
    "film_language_encoder_kwargs = {\n",
    "    'encoder_type': 'gru',\n",
    "    'decoder_type': 'linear',\n",
    "    'null_token': None,\n",
    "    'encoder_vocab_size': None,\n",
    "    'wordvec_dim': 200,\n",
    "    'hidden_dim': 1024,\n",
    "    'rnn_num_layers': 1,\n",
    "    'rnn_dropout': 0,\n",
    "    'parameter_efficient': True,\n",
    "    'output_batchnorm': False,\n",
    "    'bidirectional': False,\n",
    "    'gamma_option': 'linear', # not used\n",
    "    'gamma_baseline': 1, # not used\n",
    "    'use_attention': False, # not used\n",
    "    \"num_modules\": None,\n",
    "}\n",
    "\n",
    "mac_kwargs = {\n",
    "    'vocab': None,\n",
    "    'feature_dim': None, # raw images: [3,128,128]; resnet18 features: [256, 14, 14]\n",
    "    'stem_num_layers': 6,\n",
    "    'stem_batchnorm': True,\n",
    "    'stem_kernel_size': [3],\n",
    "    'stem_subsample_layers': [1,3], # add MaxPool2d(kernel_size=2, stride=2)\n",
    "    'stem_stride': [1],\n",
    "    'stem_padding': None,\n",
    "    'stem_dim': 64,\n",
    "    'num_modules': None,\n",
    "    'module_dim': 128,\n",
    "    'question_embedding_dropout': 0.,\n",
    "    'stem_dropout': 0.,\n",
    "    'memory_dropout': 0.,\n",
    "    'read_dropout': 0.,\n",
    "    'nonlinearity': 'ELU',\n",
    "    'use_prior_control_in_control_unit': 0 == 1,\n",
    "    'use_self_attention': 0,\n",
    "    'use_memory_gate': 0,\n",
    "    'question2output': 1,\n",
    "    'classifier_batchnorm': 0 == 1,\n",
    "    'classifier_fc_layers': [1024],\n",
    "    'classifier_dropout': 0.,\n",
    "    'use_coords': 1, # 1, 0\n",
    "    'write_unit': 'original',\n",
    "    'read_connect': 'last',\n",
    "    'noisy_controls': bool(0),\n",
    "    'debug_every': float('inf'),\n",
    "    'print_verbose_every': float('inf'),\n",
    "    'hard_code_control' : False\n",
    "    }\n",
    "    \n",
    "film_kwargs = {\n",
    "    'vocab': None,\n",
    "    'feature_dim': None, # raw images: [3,128,128]; resnet18 features: [256, 14, 14]\n",
    "    'stem_num_layers': 6,\n",
    "    'stem_batchnorm': True,\n",
    "    'stem_kernel_size': [3],\n",
    "    'stem_subsample_layers': [1,3], # add MaxPool2d(kernel_size=2, stride=2)\n",
    "    'stem_stride': [1],\n",
    "    'stem_padding': None,\n",
    "    'stem_dim': 64,\n",
    "    'num_modules': None,\n",
    "    'module_num_layers': 1,\n",
    "    'module_dim': 64, #was 128 in original FiLM`\n",
    "    'module_residual': True,\n",
    "    'module_intermediate_batchnorm': False,\n",
    "    'module_batchnorm': True,\n",
    "    'module_batchnorm_affine': False,\n",
    "    'module_dropout': 0e-2,\n",
    "    'module_input_proj': 1,\n",
    "    'module_kernel_size': 3,\n",
    "    'classifier_proj_dim': 512,\n",
    "    'classifier_downsample': 'maxpool2',\n",
    "    'classifier_fc_layers': [1024],\n",
    "    'classifier_batchnorm': True,\n",
    "    'classifier_dropout': 0,\n",
    "    'condition_method': 'bn-film',\n",
    "    'condition_pattern': None, # [1,1,1,1], # length should be equal to \"num_modules\"\n",
    "    'use_gamma': True,\n",
    "    'use_beta': True,\n",
    "    'use_coords': 1, # 1, 0\n",
    "    'debug_every': float('inf'),\n",
    "    'print_verbose_every': float('inf'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "welcome-offset",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def load_checkpoint(checkpoint):\n",
    "    if os.path.isfile(checkpoint):\n",
    "        print(\"=> loading checkpoint '{}'\".format(checkpoint))\n",
    "        cp = torch.load(checkpoint)\n",
    "        return cp\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(checkpoint))\n",
    "        raise Exception(\"No checkpoint found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "adapted-heath",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '/data/mli/qsr-learning/qsr-learning/data/intrinsic/torch_random_seed_1/num_entity_5/excluded_entity_18_excluded_relation_all4/image_size_128_emoji_size_24/2021-03-28 23:30:41.039363+02:00_mac_num_modules_2/Checkpoints/ckpt_final.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "#### 2 entities, intrinsic\n",
    "# root_datadir = '/data/mli/qsr-learning/qsr-learning/data/intrinsic/torch_random_seed_1/num_entity_2/excluded_entity_18_excluded_relation_all4/image_size_128_emoji_size_24/'\n",
    "# checkpoint_dirname = '2021-03-28 11:15:14.474585+02:00_film_num_modules_4' \n",
    "# checkpoint_dirname = '2021-03-28 23:12:55.798907+02:00_mac_num_modules_2'\n",
    "\n",
    "#### 5 entities, intrinsic\n",
    "root_datadir = '/data/mli/qsr-learning/qsr-learning/data/intrinsic/torch_random_seed_1/num_entity_5/excluded_entity_18_excluded_relation_all4/image_size_128_emoji_size_24/'\n",
    "checkpoint_dirname = '2021-03-28 23:30:41.039363+02:00_mac_num_modules_2'\n",
    "checkpoint_filename = 'final'\n",
    "checkpoint_path = os.path.join(root_datadir, checkpoint_dirname, 'Checkpoints', 'ckpt_{}.pth.tar'.format(checkpoint_filename))\n",
    "model_type = 'mac'\n",
    "number_modules = 2\n",
    "num_entity = 5\n",
    "reference_type = 'intrinsic'\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "cp = load_checkpoint(checkpoint_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "compliant-element",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_encoder = None\n",
    "model = None\n",
    "vocab = None\n",
    "vocab = cp['vocab']\n",
    "len(vocab['question_token_to_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "advanced-celebration",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vr.models import MAC, FiLMedNet, FiLMGen\n",
    "if model_type == \"mac\":\n",
    "    mac_language_encoder_kwargs['null_token'] = vocab['question_token_to_idx']['NULL']\n",
    "    mac_language_encoder_kwargs['encoder_vocab_size'] = len(vocab['question_token_to_idx'])\n",
    "    mac_language_encoder_kwargs['num_modules'] = number_modules\n",
    "    mac_kwargs['vocab'] = vocab\n",
    "    mac_kwargs['feature_dim'] = [3,128,128]\n",
    "    mac_kwargs['num_modules'] = number_modules\n",
    "    language_encoder = FiLMGen(**mac_language_encoder_kwargs).to(device)\n",
    "    model = MAC(**mac_kwargs).to(device)\n",
    "elif model_type == \"film\":\n",
    "    film_language_encoder_kwargs['null_token'] = vocab['question_token_to_idx']['NULL']\n",
    "    film_language_encoder_kwargs['encoder_vocab_size'] = len(vocab['question_token_to_idx'])\n",
    "    film_language_encoder_kwargs['num_modules'] = number_modules\n",
    "    film_kwargs['vocab'] = vocab\n",
    "    film_kwargs['feature_dim'] = [3,128,128]\n",
    "    film_kwargs['num_modules'] = number_modules\n",
    "    film_kwargs['condition_pattern'] = [1] * number_modules\n",
    "    language_encoder = FiLMGen(**film_language_encoder_kwargs).to(device)\n",
    "    model = FiLMedNet(**film_kwargs).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "straight-bridal",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_encoder.load_state_dict(cp[\"language_encoder_state\"])\n",
    "model.load_state_dict(cp[\"model_state\"])\n",
    "language_encoder.eval()\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-placement",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "finite-denial",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsr_learning.entity import emoji_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "supreme-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_names = [\n",
    "    \"slightly smiling face\",\n",
    "    \"nerd face\",\n",
    "    \"smiling face with halo\",\n",
    "    \"expressionless face\",\n",
    "    \"flushed face\",\n",
    "    \"face with tears of joy\",\n",
    "    \"neutral face\",\n",
    "    \"smiling face with heart-eyes\",\n",
    "    \"face with medical mask\",\n",
    "    \"loudly crying face\",\n",
    "    \"hugging face\",\n",
    "    \"smiling face with smiling eyes\",\n",
    "    \"squinting face with tongue\",\n",
    "    \"face with steam from nose\",\n",
    "    \"dog face\",\n",
    "    \"cat face\",\n",
    "    \"face screaming in fear\",\n",
    "    \"pouting face\",\n",
    "    \"pig face\",\n",
    "    \"rabbit face\",\n",
    "    \"tiger face\",\n",
    "    \"monkey face\",\n",
    "    \"cow face\",\n",
    "    \"tired face\",\n",
    "    \"mouse face\",\n",
    "    \"dragon face\",\n",
    "    \"face with tongue\",\n",
    "    \"sun with face\",\n",
    "    \"worried face\",\n",
    "    \"dizzy face\",\n",
    "    \"face with open mouth\",\n",
    "    \"fearful face\",\n",
    "]\n",
    "\n",
    "excluded_entity_names = [\n",
    "    \"hugging face\",\n",
    "    \"fearful face\",\n",
    "    \"face with steam from nose\",\n",
    "    \"face with tongue\",\n",
    "    \"nerd face\",\n",
    "    \"expressionless face\",\n",
    "    \"dragon face\",\n",
    "    \"flushed face\",\n",
    "    \"cow face\",\n",
    "    \"smiling face with heart-eyes\",\n",
    "    \"sun with face\",\n",
    "    \"pig face\",\n",
    "    \"pouting face\",\n",
    "    \"smiling face with halo\",\n",
    "    \"slightly smiling face\",\n",
    "    \"worried face\",\n",
    "    \"neutral face\",\n",
    "    \"loudly crying face\",\n",
    "]\n",
    "\n",
    "relation_names_abs_intri = [\"left_of\", \"right_of\", \"above\", \"below\"]\n",
    "excluded_relation_names_all4_abs_intri = [\"left_of\", \"right_of\", \"above\", \"below\"]\n",
    "\n",
    "\n",
    "relation_names_rel = [\"left_of\", \"right_of\", \"in_front_of\", \"behind\"]\n",
    "excluded_relation_names_all4_rel = [\"left_of\", \"right_of\", \"in_front_of\", \"behind\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "excited-edwards",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reference_type == \"intrinsic\" or args.reference_type == \"absolute\":\n",
    "        relation_names = relation_names_abs_intri\n",
    "        excluded_relation_names = excluded_relation_names_all4_abs_intri\n",
    "        pass\n",
    "elif reference_type == \"relative\":\n",
    "    relation_names = relation_names_rel\n",
    "    excluded_relation_names = excluded_relation_names_all4_rel\n",
    "    pass\n",
    "else:\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ancient-carol",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.dataset = Munch(\n",
    "        vocab=list(vocab[\"question_token_to_idx\"].keys()),\n",
    "        entity_names=entity_names,\n",
    "        relation_names=relation_names,\n",
    "        num_entities=num_entity,\n",
    "        frame_of_reference= \"intrinsic\", # \"intrinsic\" or \"absolute\"\n",
    "        w_range=(24, 24), #(8, 8) (16, 16) (24, 24) (32, 32)\n",
    "        h_range=(24, 24), #(8, 8)\n",
    "        theta_range=(0, 2 * math.pi),\n",
    "        add_bbox=False,\n",
    "        add_front=False,\n",
    "        transform=None,\n",
    "        canvas_size=(128, 128), #(224, 224) (128, 128) (64, 64)\n",
    "        num_samples=1000,\n",
    "        root_seed=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "involved-hayes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "config.data_loader = Munch(\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "test_dataset = DRLDataset(\n",
    "            **{\n",
    "                **config.dataset,\n",
    "                **dict(\n",
    "                    entity_names=excluded_entity_names,\n",
    "                    excluded_entity_names=[],\n",
    "                    relation_names=excluded_relation_names,\n",
    "                    excluded_relation_names=[],\n",
    "                    num_samples=100,\n",
    "                    root_seed=10 ** 7,\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "test_loader = DataLoader(\n",
    "        test_dataset, **{**config.data_loader, \"shuffle\": False}\n",
    "    )\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "discrete-comedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6cefd526d2454c9f0712089b2b9c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='frame_of_reference', max=1), IntSlider(value=30, descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 2 entities\n",
    "from ipywidgets import interact\n",
    "from qsr_learning.binary_relation import above, below, left_of, right_of\n",
    "from qsr_learning.data import DRLDataset\n",
    "\n",
    "import math\n",
    "from PIL import Image\n",
    "from qsr_learning.entity import Entity\n",
    "\n",
    "dataset = test_dataset\n",
    "\n",
    "question = [\"face with open mouth\", \"below\", \"hugging face\"]\n",
    "question_t = torch.tensor([dataset.word2idx[w] for w in question], dtype=torch.long)\n",
    "# answer = 0\n",
    "# answer_t = torch.tensor(answer, dtype=torch.float)\n",
    "\n",
    "@interact(\n",
    "    frame_of_reference=(0, 1),\n",
    "    x1=(0, 105),\n",
    "    y1=(0, 105),\n",
    "    theta1=(0, 360),\n",
    "    x2=(0, 105),\n",
    "    y2=(0, 105),\n",
    "    theta2=(0, 360),\n",
    ")\n",
    "def test_spatial_relations(\n",
    "    frame_of_reference=0, x1=30, y1=30, theta1=0, x2=64, y2=64, theta2=150\n",
    "):\n",
    "    canvas = Image.new(\"RGBA\", (128, 128), (0, 0, 0, 255))\n",
    "    entity1 = Entity(\n",
    "        name=\"face with open mouth\",\n",
    "        frame_of_reference={0: \"absolute\", 1: \"intrinsic\"}[frame_of_reference],\n",
    "        p=(x1, y1),\n",
    "        theta=theta1 / 360 * 2 * math.pi,\n",
    "        size=(24, 24),\n",
    "    )\n",
    "    entity1.draw(canvas, add_bbox=False, add_front=False)\n",
    "    entity2 = Entity(\n",
    "        name=\"hugging face\",\n",
    "        frame_of_reference={0: \"absolute\", 1: \"intrinsic\"}[frame_of_reference],\n",
    "        p=(x2, y2),\n",
    "        theta=theta2 / 360 * 2 * math.pi,\n",
    "        size=(24, 24),\n",
    "    )\n",
    "    entity2.draw(canvas, add_bbox=False, add_front=False)\n",
    "    background = Image.new(\"RGBA\", canvas.size, (0, 0, 0))\n",
    "    image = Image.alpha_composite(background, canvas).convert(\"RGB\")\n",
    "    display(image)\n",
    "    \n",
    "    image_t = dataset.transform(image)\n",
    "    questions_var = question_t.unsqueeze(0).to(device)\n",
    "    questions_feat = language_encoder(questions_var)\n",
    "    images_var = image_t.unsqueeze(0).to(device)\n",
    "    if model_type == \"mac\":\n",
    "        scores = model(images_var, questions_feat, isTest=True)\n",
    "    elif model_type == \"film\":\n",
    "        scores = model(images_var, questions_feat)\n",
    "        \n",
    "    if scores is not None:\n",
    "        _, preds = scores.data.cpu().max(1)\n",
    "        print(\"Question:\", ' '.join(question))\n",
    "        print(\"Prediction: \", bool(preds.item()))\n",
    "        print(\"scores:\", scores.data.softmax(dim=1)[0,1].item())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "rational-austin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ff7c0d741e24882a06aa242905f505b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='frame_of_reference', max=1), IntSlider(value=30, descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 5 entities\n",
    "from ipywidgets import interact\n",
    "from qsr_learning.binary_relation import above, below, left_of, right_of\n",
    "from qsr_learning.data import DRLDataset\n",
    "\n",
    "import math\n",
    "from PIL import Image\n",
    "from qsr_learning.entity import Entity\n",
    "\n",
    "dataset = test_dataset\n",
    "\n",
    "question = [\"face with tongue\", \"above\", \"nerd face\"]\n",
    "question_t = torch.tensor([dataset.word2idx[w] for w in question], dtype=torch.long)\n",
    "# answer = 0\n",
    "# answer_t = torch.tensor(answer, dtype=torch.float)\n",
    "\n",
    "@interact(\n",
    "    frame_of_reference=(0, 1),\n",
    "    x1=(0, 105),\n",
    "    y1=(0, 105),\n",
    "    theta1=(0, 360),\n",
    "    x2=(0, 105),\n",
    "    y2=(0, 105),\n",
    "    theta2=(0, 360),\n",
    "    x3=(0, 105),\n",
    "    y3=(0, 105),\n",
    "    theta3=(0, 360),\n",
    "    x4=(0, 105),\n",
    "    y4=(0, 105),\n",
    "    theta4=(0, 360),\n",
    "    x5=(0, 105),\n",
    "    y5=(0, 105),\n",
    "    theta5=(0, 360),\n",
    ")\n",
    "def test_spatial_relations(\n",
    "    frame_of_reference=0, x1=30, y1=30, theta1=0, x2=64, y2=64, theta2=150, \\\n",
    "    x3=10, y3=10, theta3=0, x4=70, y4=10, theta4=150, x5=10, y5=60, theta5=0\n",
    "):\n",
    "    canvas = Image.new(\"RGBA\", (128, 128), (0, 0, 0, 255))\n",
    "    entity1 = Entity(\n",
    "        name=\"nerd face\",\n",
    "        frame_of_reference={0: \"absolute\", 1: \"intrinsic\"}[frame_of_reference],\n",
    "        p=(x1, y1),\n",
    "        theta=theta1 / 360 * 2 * math.pi,\n",
    "        size=(24, 24),\n",
    "    )\n",
    "    entity1.draw(canvas, add_bbox=False, add_front=False)\n",
    "    entity2 = Entity(\n",
    "        name=\"face with tongue\",\n",
    "        frame_of_reference={0: \"absolute\", 1: \"intrinsic\"}[frame_of_reference],\n",
    "        p=(x2, y2),\n",
    "        theta=theta2 / 360 * 2 * math.pi,\n",
    "        size=(24, 24),\n",
    "    )\n",
    "    entity2.draw(canvas, add_bbox=False, add_front=False)\n",
    "    \n",
    "    entity3 = Entity(\n",
    "        name=\"slightly smiling face\",\n",
    "        frame_of_reference={0: \"absolute\", 1: \"intrinsic\"}[frame_of_reference],\n",
    "        p=(x3, y3),\n",
    "        theta=theta3 / 360 * 2 * math.pi,\n",
    "        size=(24, 24),\n",
    "    )\n",
    "    entity3.draw(canvas, add_bbox=False, add_front=False)\n",
    "    \n",
    "    entity4 = Entity(\n",
    "        name=\"cow face\",\n",
    "        frame_of_reference={0: \"absolute\", 1: \"intrinsic\"}[frame_of_reference],\n",
    "        p=(x4, y4),\n",
    "        theta=theta4 / 360 * 2 * math.pi,\n",
    "        size=(24, 24),\n",
    "    )\n",
    "    entity4.draw(canvas, add_bbox=False, add_front=False)\n",
    "    \n",
    "    entity5 = Entity(\n",
    "        name=\"pig face\",\n",
    "        frame_of_reference={0: \"absolute\", 1: \"intrinsic\"}[frame_of_reference],\n",
    "        p=(x5, y5),\n",
    "        theta=theta5 / 360 * 2 * math.pi,\n",
    "        size=(24, 24),\n",
    "    )\n",
    "    entity5.draw(canvas, add_bbox=False, add_front=False)\n",
    "    \n",
    "    background = Image.new(\"RGBA\", canvas.size, (0, 0, 0))\n",
    "    image = Image.alpha_composite(background, canvas).convert(\"RGB\")\n",
    "    display(image)\n",
    "    \n",
    "    image_t = dataset.transform(image)\n",
    "    questions_var = question_t.unsqueeze(0).to(device)\n",
    "    questions_feat = language_encoder(questions_var)\n",
    "    images_var = image_t.unsqueeze(0).to(device)\n",
    "    if model_type == \"mac\":\n",
    "        scores = model(images_var, questions_feat, isTest=True)\n",
    "    elif model_type == \"film\":\n",
    "        scores = model(images_var, questions_feat)\n",
    "        \n",
    "    if scores is not None:\n",
    "        _, preds = scores.data.cpu().max(1)\n",
    "        print(\"Question:\", ' '.join(question))\n",
    "        print(\"Prediction: \", bool(preds.item()))\n",
    "        print(\"scores:\", scores.data.softmax(dim=1)[0,1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "different-lexington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128 at 0x7F283C521D30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['face with tongue', 'below', 'pig face']\n",
      "Ground truth:  False\n",
      "Prediction:  True\n",
      "scores: 0.9806837439537048\n",
      "wroung!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128 at 0x7F283C521518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pig face', 'below', 'flushed face']\n",
      "Ground truth:  False\n",
      "Prediction:  True\n",
      "scores: 0.8370379209518433\n",
      "wroung!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAH+0lEQVR4nO3aW2wcVxkA4P/MfXa8Xq93vY53fVnbcRw7cVwnjpM4tEAiJRKIihYFUhUBpSBeEEUqlWgFUSoF0SpUoAQoUvNSiSAq8dCGtqCWNGkKJGmAxJGTPDiXOr7uxbve29xnDg9rorQSSCWTjr35v7eV7Pn/Pf/85+ycMwAIIYQQQgghhBBCCCGEEEIIIYQQQgihWkM+sUiU0g8FJp9c6OWM8/ZyHxnl290+4v/jz+41d3obfmQoN7eSvzwObEhWgSgy8DyUVZpfcGcy7rUMKZniE8dK1f/CDqjyoAC3hjKqQOZF3pRih9+mhaK1eQ0bCsCmLhog5kLGckv21Kw7mYIvvWJiAW7xrABjj0DvZzhx84gZSm778rm+hHn/fXxYJPm8+5VRCPGVSk6v5Mz0rKXmhC1HyliAKg/WAAJAAcIbQPzUDuj69NzEZE8L+e3BGDRTqDhHjxpvXYI9o3Idnycsw7LEVKzBOMEmqGLu/BIU4Hdfg7bta6DrYZACFsP2rQlOFejs+XJ5xhjdKOQs7s/vlWfzohwUlUbBEJiT31HuPG5tuNMOIIRQShcPEtiwl3JxApP1kUBDc/D0m9eLV+eSXQGlt725WUhIdcdP3XjgPrejWYk28WTB9iT7GuBBBwBA3UAHFQYJEwZXiK0KyHWBqbSrhIXZMvv3Ma2tGTZsEjrWDk3yDy26cUG0eRl/hi7xpgDQ3k/kdgoBaosAXKJVmWEiN5VVwTXNo1ulvk4CVB0aTgYHv/8Bs0u3rLKjexN35fOoAFIUoJEAD1QAYPsHgm++Y/3kVwXNhM3reGUVBxaVeJ1hJYONAaUcCwDwYM+wN9FXMo+ehB0LgACwhBAAUipamwa4Bx+oEwX6p/eMzpi7fq1UmtIWi++2sxdknjgQAIBjE//wJvpK5k0HUHUKIAOEBWIDuJlZtbux8tURQ5xPF1LalSmSm+JTN67dPH6gUzplOnUlFdeAJR5NQZlrUD5LCQFiW4ZtmVRf1C+cWshcK61vJdEw9/rJ8vx0cWSAAU2vVOxU1nlqVMIdIfCqANyxtJ15lcAUMILj2I4NrV31e5/s2/FIR++GINVd6nLDg0p3CynlbVDty9Puz04bnoRe6TwoACGEHHK4G2fo5EvAuCxl60Rhcs4VWuWOjaFSBc5d1LevpcGgZauGVrDm513V4e88bm3wbDu671H1yqHXQM9zjYM9bfz5Cfb5/enkKtYou/1Rd3XUsXKqmtHTM2a+KH/zD0Wv4q503uzGVDd2/roHeoahaX2cJLufPZwbu5jZOUAGkjDa7VLTmp42RM2O7zc/FB63gzxRXU5FBgDg9ceA/nf1ks+pLjeedcDtH3++g3x3J7gSly3T1v3Ox70OtoVvqgWo9orfudx7KKUgBZc+RBO3Zi1fk7rrllGzU0rJk2/AdEoMrSOJLYwI0oKey9v0SB3U7ry0XL4VpTTyxQMNO3/UKUEvgfYwiEBdjkyV7IszzqlJ2/r10hlOjVXC49dS/j+fP/xHANi255luW+1gS51REm+JxULEIZTnuFyFe+U8v2afMdFWhuc21thCvSy+BqX08UNvN8nBS1fGCbDpQnrrui3b1g23RKVYAyvyNF9m3rjgHhrXsyf2wZkXoIZ+L/nfAS/u2w0AGyMzQCJMV0swEAF3yLSIphqpLMkXOFkisRC/d5hJO4Ej6Uf1My/Af45C/c7dA/7fQZTSU0cfNgJtFaZZI0nTknQnahoBhpEZtkFgRV5g5vLpxmAwFokfvkqOKwDPrKc3xmvg9gffO+BfP5AAoLd+2grqOSs1PjGWSdOu4ft1vl6zwpoVUy2J6sGrk9fHboztGtndGdgo/u2E8cElf9P2kM8FGDqoLfyyLpSMszzLkPLU6SupBWdokOlItKTysaKeMsz6it063N8ZbpAvT/yzvTfU3d1/qYbeKfJ/DeAklmMdxrZDvDsyFDQp0xufDzSUZZqxmIZsIZSt5DUz0tIYzRUVgaSjjAnQ7HfWnvGzAJTS177Obx2RQq5JqRPg+c9+Lm5bNisZhmW1KKqg5FOXtfPvvtU7PNCS2BLsjWTVdELLAvT5mLa3fO6AtTGeo2CqhsBpIIhguJzIAE9Ey+F4zShWyjczxvWZtlExKHMFElJo4w+/8XTNzD/gYwEopU11/O/3inLEUiICgG6qRmrKnM3oogQ9/SElIXMAI1vCyVahY7XL8Ddzpi2pAsDTfuV8N/jZAdmKPT5DelpIsWBJDcaV8bmTZ/KOZWgaJJINu77QHk/IiSahtUmyVNfVFyR3sfuxiXd+3OZjzp7z6K2Ij+nWM9RvzruSyINqlxcMBsz2NqExKq/uFhfTixfPZkAnpAw0r7GVArs4Z6fTALDzwLQvOd8l/nRAdRKvluGhAe6J7UwPawx0Kp3t0kKJTs5ahQpJzZYr2bwSIKCrYJuFTCXy7eLZ79Xaab7/q1m1DOWfBpwA4cKi0iC4lJ1MO7Zu9fQIRtHSVRdMJz1j9Dyr19LyW+X/cwAhhGHAcZYmpfQvBF6WWuv5EnEr81qpaGsFO0zYV9+nT/mb6N2xvG6obw2veuncHACUng9cz7odYSa3CAZxX34fnjtRg7f/chSVmuvlpWPhtRHYnVya9Gtj73OFuXUmjKPvp3vhaB4hhBBCCCGEEEIIIYQQQgghhBBCCCGEEEIIIYQQQgghhBBCCCGEEEIIIYQQQgghhBBCCCGEEEIIIQT/BsR4jCfJH/73AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128 at 0x7F283C521E80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nerd face', 'below', 'fearful face']\n",
      "Ground truth:  False\n",
      "Prediction:  True\n",
      "scores: 0.9880157113075256\n",
      "wroung!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128 at 0x7F283C521EF0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pouting face', 'below', 'smiling face with heart-eyes']\n",
      "Ground truth:  False\n",
      "Prediction:  True\n",
      "scores: 0.5272389054298401\n",
      "wroung!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128 at 0x7F283C521E80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral face', 'below', 'face with steam from nose']\n",
      "Ground truth:  False\n",
      "Prediction:  True\n",
      "scores: 0.997940719127655\n",
      "wroung!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128 at 0x7F283C521668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['worried face', 'above', 'sun with face']\n",
      "Ground truth:  True\n",
      "Prediction:  False\n",
      "scores: 0.03959401696920395\n",
      "wroung!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128 at 0x7F283C521D68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['slightly smiling face', 'below', 'loudly crying face']\n",
      "Ground truth:  False\n",
      "Prediction:  True\n",
      "scores: 0.922211766242981\n",
      "wroung!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128 at 0x7F283C521BE0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hugging face', 'above', 'fearful face']\n",
      "Ground truth:  False\n",
      "Prediction:  True\n",
      "scores: 0.8315033912658691\n",
      "wroung!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAIHElEQVR4nO3cWWxU1xkH8O+cu854xrN5Y2yMN8AsBgoNJNBATctDQ6IGIlWRSqiKVBTlIU2TtlIVqlRRky5SRRqp6kJKH1qo+lCVVA0JIUtZ63QxEHArzFIb423s8ax37tz168OUJe6Y2pPGo5rv9+TRSFffnP8959x77j0GIIQQQgghhBBCCCGEEEIIIWWAiIhY7iruCuJUXzDGbs+AMTYr9dx1pgwAACTG7Bt/UxgfkSIBIGKhiW2AXWF4Nw/77+cjW5RIox+jqmvYFMb/UJHmuxlAtQixL6jQVgPVUbetkUt+8MqYyTpjcbx23e3rG/1huvFGGJREaYoHUMnYY63w7DpPdEMTLF2JkXngUYGLaNsMXCZw0DU8e37s0F9eeD/78qVbmZGZKh6AuZWNV6jRZdV2W5NQV4+BIDAOjDFBQkkCzpkkM9eCv3cPHTq16pdazMbbJwwyfXzS58K5rClKVb3P9aqg6ZBJg5YD0wTTBENneo7lNExNuDndblkS3bIiZuOXgtT6JSp+FcRVUVIFy7R4Tse8zsFAGxAYcA62VegNINiCKEJNFADetma36jlkcg8AgOEHREEA23Il284mc+fPXE9eGWaWxkwDHAcdFy2TGTpkMjgybE+kAGD/fdKsVz5HFAkAHBQY2BZapoOWPTiiHXqtN9ZzjU3EnUSC5zLc0pxkgmsJHo/x8RgAtHrY7qrZLn1u+EAAhQlAZIwBOC66NoY8sKFJ7utPnTjZb8TjYjYB46PXzlw913X1SnefMTLOnziHe+pDFcLPxsv1E/6/FZkDJHQd03VMR1YFXbPf6slcHNDbahUFjOxI/g+nYxeuZJa3BZZEVQYMAJhh2bRuVKrJATw5H4Y0NyI7smxbIvdUct3C5qhnY3sFWEYyZp46n2oIS4+u85lZi5kWABgJ09SdchQ/F0yeA14eAFXiFYCObttZS0+bmxeqT20OzvMCZAwJHEURJQ6pCV1mjpGzAcDKmmi55Sh+LrjVAwoTQLMHaiQ3a3CFu7ZucwGqfOzymHNBc9tr5WiVvH21r97HVcfNp13f3lh+p8/M2XVv0G1AiT4wBBUy2N0DB+6145rIEQyEc3H3TyNuX8IO9uZ3rfGub1C0lGWl0TEdFcDIWLZJM0DpbgVQWMy5udIZeURI6Wi6UMdx2wKxukM9Nuz0xqx6wbEN17GR2Q4ApJJOo4cmgNIVX0FbF4SuxK3zWntYdhnTBZ4yIcBRBOCItoVVh82vNLNfDcI43QmXqvhSxHtJqJbZ2BZ53HQYZ5EjFgD4ATwPSVoOFAk0B2resLo62ek0tf6HMq015MFPcw6MM1bz5r8bO76ZRd6hJehy+GorhxtP7e/0PJN81OjkJ4QQQgghhBBC7ka0kaKcCq1P+1nK5vZ2pxhmW9HmnmkGtKJcIkQUGAOA+iCvD/C1dfLG+cLZEWP3GqmQwTQfltCicokQ0SsxkcP3HpS3tPMgsAnNiQaEvhTKImZtWP1SHqYRA/WAUhReH/lOp7xjnVgRdCzGuS0FORfBaa4yIagImL7+omLm+X/dukIBlOjjDbBrE3e9zA14KpggpgU7a8fVlliwOeevC4jDzeEuMTs28i35ziMSDUEzhog/fZC11InrVypKtUd3uN/rMWJyMs77Fj8eWrej0uczDKf/2IvL1d8Fs6P8avKRfe5v+4vHUOz1dDI1RAyrTFJ4x0JZiqjjhvTqu3rCqFDCLNG8Ibj2sXx88Jtff3J86HJwyc4h1gGLm6DV19EKjLFJW68LKIAZ83lgU7vsCYjcK7/Tla4MVYZaQ25d2PSjh4uvvX7klX37Tp44Fo5EJswK3rgC2hbev0YAKL6VkeaAGSi04M+3K3VhLgek9y9bqaz40AO1AC4PWkF3OJ0afebpLy9atPgTG+4bHhyf3+KLxZOjF4VPdaq/Pq4BAAOY1AWoB0wXIgoCEwGaI3zCAdMCr4ifvLfGX+8FGUCy66rGePzHPT1XVq+65/o/L+fG9zdE48jDMT0CNcFH30PG2H/epFEPmAHXBRdgIGmulGTusPZ6P8g+TJssZGY01e8fWBg5MGb2TgxAdVCNLPJL4WU9b55JZQXw1kx1TApgWm4O3wuDwtY2JZ91JeRmwrS8qUuZDXlrhcEbgtrZpsixaFtvFFvA4wFoTA7ygQtDn336a1D78C+20WXoh3Pzcr77CV+1zw54K8BwB+Zvzax9ZkHjIll0XPT1nNqzasXJypr5AHUgzGNy08RoVbh2E74e1fYO+48WOSzNAdPFGOOMIWLXgKPl0XVdLooxtWX5x1b95Eff3fH5zw0PXVHDGzOZaibKwINMbABcEKqtBwBTdou2PtAQNCN4279Rij1bCT5RVNxkBnp7L3d3/81FXZZCmawIUq2jh0QeBAwxaLWv7nQzo1Mdk3rAjDHGHr9HrHkhLas5b/J4bqL/4MGDh4/+edmS9vhYT7RBBQidfvXkaJ8FzAYA7Dvi3Tb10Wav8Lml5yll6d48AFw4tDtV+RlZ9SdHe5Ytujhvnn72r+KZty598dvPMbnTPLFU2fiPOxyHhqASLXvJOC8qlQFcvsdM/L7D1MWlixvkytDxo2Z8ML1++yomd1oHQpaWLHelc13/c0rhYaT1x5Vud6f59ko81Z44XIuI328td3F3idFvgPE8IOLV5/lvdgL+ABCRZtcyKHSFjkoKoKzo3QhCCCGEEEIIIYQQQgghhBBCCCGEEEIIIYQQQgghhBBCCCGEEEIIIYQQQgghhBBCCCGEzAH/Aom8s51VhuRrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128 at 0x7F283C521710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flushed face', 'below', 'pouting face']\n",
      "Ground truth:  False\n",
      "Prediction:  True\n",
      "scores: 0.925116240978241\n",
      "wroung!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128 at 0x7F283C521EF0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['face with tongue', 'right_of', 'cow face']\n",
      "Ground truth:  False\n",
      "Prediction:  True\n",
      "scores: 0.9991514682769775\n",
      "wroung!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128 at 0x7F283C521BE0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dragon face', 'left_of', 'sun with face']\n",
      "Ground truth:  True\n",
      "Prediction:  False\n",
      "scores: 0.23071053624153137\n",
      "wroung!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128 at 0x7F283C521BA8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hugging face', 'below', 'pouting face']\n",
      "Ground truth:  False\n",
      "Prediction:  True\n",
      "scores: 0.9928779006004333\n",
      "wroung!\n",
      "cnt:12\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "cnt = 0\n",
    "dataset = test_dataset\n",
    "for idx in range(len(dataset)):\n",
    "    image_t, question_t, answer_t = dataset[idx]\n",
    "    questions_var = question_t.unsqueeze(0).to(device)\n",
    "    questions_feat = language_encoder(questions_var)\n",
    "    images_var = image_t.unsqueeze(0).to(device)\n",
    "    answers_var = answer_t.unsqueeze(0).type(torch.LongTensor).to(device)\n",
    "    if model_type == \"mac\":\n",
    "        scores = model(images_var, questions_feat, isTest=True)\n",
    "    elif model_type == \"film\":\n",
    "        scores = model(images_var, questions_feat)\n",
    "\n",
    "    if scores is not None:\n",
    "        _, preds = scores.data.cpu().max(1)\n",
    "        if preds == answer_t:\n",
    "            pass\n",
    "            # print(\"correct!\")\n",
    "        else:\n",
    "            cnt += 1\n",
    "            image = Image.fromarray(\n",
    "                (255 * (dataset.std.view(-1, 1, 1) * image_t + dataset.mean.view(-1, 1, 1)))\n",
    "                .permute(1, 2, 0)\n",
    "                .numpy()\n",
    "                .astype(\"uint8\")\n",
    "            )\n",
    "            question = [dataset.idx2word[idx] for idx in question_t.tolist()]\n",
    "            display(image)\n",
    "            print(question)\n",
    "            print(\"Ground truth: \", bool(answer_t))\n",
    "            print(\"Prediction: \", bool(preds.item()))\n",
    "            print(\"scores:\", scores.data.softmax(dim=1)[0,1].item())\n",
    "            print(\"wroung!\")\n",
    "print(\"cnt:{}\".format(cnt))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "flying-yukon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "216187fd6beb4eb5b6e49a363e4723ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='idx', max=999), Output()), _dom_classes=('widget-interac…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "from PIL import Image\n",
    "dataset = test_dataset\n",
    "@interact(idx=(0, len(dataset) - 1))\n",
    "def display_sample(idx=0):\n",
    "\n",
    "    image_t, question_t, answer_t = dataset[idx]\n",
    "    image = Image.fromarray(\n",
    "        (255 * (dataset.std.view(-1, 1, 1) * image_t + dataset.mean.view(-1, 1, 1)))\n",
    "        .permute(1, 2, 0)\n",
    "        .numpy()\n",
    "        .astype(\"uint8\")\n",
    "    )\n",
    "\n",
    "    question = [dataset.idx2word[idx] for idx in question_t.tolist()]\n",
    "    answer = bool(answer_t)\n",
    "    display(image)\n",
    "    print(question)\n",
    "    print(\"Ground truth: \", answer)\n",
    "    \n",
    "    #(images, questions, answers) = batch # images.shape: [32, 3, 224, 224]\n",
    "    questions_var = question_t.unsqueeze(0).to(device)\n",
    "    questions_feat = language_encoder(questions_var)\n",
    "    images_var = image_t.unsqueeze(0).to(device)\n",
    "    answers_var = answer_t.unsqueeze(0).type(torch.LongTensor).to(device)\n",
    "    if model_type == \"mac\":\n",
    "        scores = model(images_var, questions_feat, isTest=True)\n",
    "    elif model_type == \"film\":\n",
    "        scores = model(images_var, questions_feat)\n",
    "\n",
    "    if scores is not None:\n",
    "        _, preds = scores.data.cpu().max(1)\n",
    "        print(\"Prediction: \", bool(preds.item()))\n",
    "        if preds == answer_t:\n",
    "            print(\"correct!\")\n",
    "        else:\n",
    "            print(\"wroung!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-andrew",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-painting",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.data_loader = Munch(\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-cosmetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, **config.data_loader)\n",
    "validation_loader = DataLoader(\n",
    "    validation_dataset, **{**config.data_loader, \"shuffle\": False}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model = Munch(\n",
    "    vision_model=\"resnet18\",\n",
    "    image_size=(3, *config.dataset.canvas_size),\n",
    "    num_embeddings=len(dataset.word2idx),\n",
    "    embedding_dim=10,\n",
    "    question_len=dataset[0][1].shape.numel(),\n",
    ")\n",
    "\n",
    "model = DRLNet(**config.model)\n",
    "lightning_checkpoint_path = (\n",
    "    \"lightning_logs/version_29/checkpoints/epoch=99-step=19599.ckpt\"\n",
    ")\n",
    "model.load_state_dict(torch.load(lightning_checkpoint_path)[\"state_dict\"])\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-praise",
   "metadata": {},
   "source": [
    "## Evaluate on manual datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from ipywidgets import interact\n",
    "from PIL import Image\n",
    "\n",
    "from qsr_learning.data import Question, draw_entities\n",
    "from qsr_learning.entity import Entity\n",
    "from qsr_learning.relation import above, below, left_of, right_of\n",
    "\n",
    "\n",
    "@interact(\n",
    "    frame_of_reference=(0, 1),\n",
    "    x1=(0, 190),\n",
    "    y1=(0, 190),\n",
    "    theta1=(0, 360),\n",
    "    x2=(0, 190),\n",
    "    y2=(0, 190),\n",
    "    theta2=(0, 360),\n",
    ")\n",
    "def test_spatial_relations(\n",
    "    frame_of_reference=1, x1=64, y1=64, theta1=0, x2=128, y2=128, theta2=150\n",
    "):\n",
    "    canvas = Image.new(\"RGBA\", (224, 224), (127, 127, 127, 127))\n",
    "    entity1 = Entity(\n",
    "        name=\"octopus\",\n",
    "        frame_of_reference={0: \"absolute\", 1: \"intrinsic\"}[frame_of_reference],\n",
    "        p=(x1, y1),\n",
    "        theta=theta1 / 360 * 2 * math.pi,\n",
    "        size=(32, 32),\n",
    "    )\n",
    "    entity2 = Entity(\n",
    "        name=\"trophy\",\n",
    "        frame_of_reference={0: \"absolute\", 1: \"intrinsic\"}[frame_of_reference],\n",
    "        p=(x2, y2),\n",
    "        theta=theta2 / 360 * 2 * math.pi,\n",
    "        size=(32, 32),\n",
    "    )\n",
    "    image = draw_entities([entity1, entity2], add_bbox=True)\n",
    "    background = Image.new(\"RGBA\", image.size, (0, 0, 0))\n",
    "    image = Image.alpha_composite(background, image).convert(\"RGB\")\n",
    "    display(image)\n",
    "    image_t = dataset.transform(image)\n",
    "    questions = []\n",
    "    answers = []\n",
    "    for relation in [right_of]:\n",
    "        questions.append(Question(entity1.name, relation.__name__, entity2.name))\n",
    "        answers.append(relation(entity1, entity2))\n",
    "    #     for relation in dataset.relations:\n",
    "    #         questions.append(Question(entity2.name, relation.__name__, entity1.name))\n",
    "    #         answers.append(relation(entity2, entity1))\n",
    "    for question, answer in zip(questions, answers):\n",
    "        question_t = torch.tensor([dataset.word2idx[word] for word in question])\n",
    "        answer_t = torch.tensor(answer)\n",
    "        with torch.no_grad():\n",
    "            pred_t = model(image_t.unsqueeze(0), question_t.unsqueeze(0))\n",
    "        score = pred_t.sigmoid().item()\n",
    "        pred = bool(pred_t.sigmoid().round())\n",
    "        print(\n",
    "            f\"\\n{question.head:7} {question.relation:8} {question.tail:7}\\n\\nGround Truth: {answer}\\nPrediction  : {pred}\\nScore       : {score:3.2f}\\nCorrect     : {answer==pred:1}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-transport",
   "metadata": {},
   "source": [
    "## Display incorrect predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-detroit",
   "metadata": {},
   "source": [
    "TODO: Getteng samples predicted incorrectly does not work yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-concern",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "idx_incorrect = []\n",
    "model.to(device)\n",
    "with tqdm(total=(len(validation_dataset) // config.data_loader.batch_size + 1)) as pbar:\n",
    "    for (i, batch) in enumerate(validation_loader):\n",
    "        batch_size = batch[0].shape[0]\n",
    "        image = batch[0].to(device)\n",
    "        question = batch[1].to(device)\n",
    "        answer = batch[2].to(device)\n",
    "        idx = torch.arange(i * batch_size, (i + 1) * batch_size)\n",
    "        idx_incorrect.extend(\n",
    "            idx[answer != model(image, question).sigmoid().round()].tolist()\n",
    "        )\n",
    "        pbar.update(1)\n",
    "model.to(torch.device(\"cpu\"))\n",
    "\n",
    "from ipywidgets import interact\n",
    "from PIL import Image\n",
    "\n",
    "subset = validation_dataset\n",
    "\n",
    "\n",
    "@interact(idx=(0, len(idx_incorrect) - 1))\n",
    "def display_sample(idx=0):\n",
    "    idx = idx_incorrect[idx]\n",
    "    image_t, question_t, answer_t = subset[idx]\n",
    "    with torch.no_grad():\n",
    "        pred_t = model(image_t.unsqueeze(0), question_t.unsqueeze(0))\n",
    "    image = Image.fromarray(\n",
    "        (255 * (dataset.std.view(-1, 1, 1) * image_t + dataset.mean.view(-1, 1, 1)))\n",
    "        .permute(1, 2, 0)\n",
    "        .numpy()\n",
    "        .astype(\"uint8\")\n",
    "    )\n",
    "    head, relation, tail = question_t.tolist()\n",
    "    question = (\n",
    "        dataset.idx2word[head],\n",
    "        dataset.idx2word[relation],\n",
    "        dataset.idx2word[tail],\n",
    "    )\n",
    "    answer = bool(answer_t)\n",
    "    pred = bool(pred_t.round())\n",
    "    display(image)\n",
    "    print(question)\n",
    "    print(\"Ground truth: \", answer)\n",
    "    print(\"Prediction: \", pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-motel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
